{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.39.2)\n",
      "Requirement already satisfied: tqdm in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n",
    "%pip install pandas\n",
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "from time import sleep\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dimitris Antoniou, URL: https://classics.columbia.edu/dimitris-antoniou\n",
      "Name: Kathy Hannah Eden, URL: https://classics.columbia.edu/kathy-hannah-eden\n",
      "Name: Chrysanthe Filippardos, URL: https://classics.columbia.edu/chrysanthe-filippardos\n",
      "Name: Marcus Folch, URL: https://classics.columbia.edu/marcus-folch\n",
      "Name: Carmela Vircillo Franklin, URL: https://classics.columbia.edu/carmela-vircillo-franklin\n",
      "Name: Hanna Golab, URL: https://classics.columbia.edu/hanna-golab\n",
      "Name: Stathis Gourgouris, URL: https://classics.columbia.edu/stathis-gourgouris\n",
      "Name: Joseph Howley, URL: https://classics.columbia.edu/joseph-howley\n",
      "Name: Elizabeth Irwin, URL: https://classics.columbia.edu/elizabeth-irwin\n",
      "Name: Nikolas P. Kakkoufa, URL: https://classics.columbia.edu/nikolas-kakkoufa\n",
      "Name: Darcy Krasne, URL: https://classics.columbia.edu/darcy-krasne\n",
      "Name: John Ma, URL: https://classics.columbia.edu/john-ma\n",
      "Name: Paraskevi Martzavou, URL: https://classics.columbia.edu/paraskevi-martzavou\n",
      "Name: Erin Petrella, URL: http://classics.columbia.edu/erin-petrella-1\n",
      "Name: Elizabeth Scharffenberger, URL: https://classics.columbia.edu/elizabeth-scharffenberger\n",
      "Name: Seth Schwartz, URL: https://classics.columbia.edu/seth-schwartz\n",
      "Name: Deborah Steiner, URL: https://classics.columbia.edu/deborah-steiner\n",
      "Name: Karen Van Dyck, URL: https://classics.columbia.edu/karen-van-dyck\n",
      "Name: Lien Van Geel, URL: https://classics.columbia.edu/lien-van-geel-1\n",
      "Name: Katharina Volk , URL: https://classics.columbia.edu/katharina-volk\n",
      "Name: Gareth Williams, URL: https://classics.columbia.edu/gareth-williams\n",
      "Name: Ellen Morris, URL: https://classics.columbia.edu/ellen-morris\n",
      "Name: Nancy Worman, URL: https://classics.columbia.edu/nancy-worman\n",
      "Name: Christopher Baswell, URL: https://classics.columbia.edu/christopher-baswell\n",
      "Name: Richard Billows, URL: https://classics.columbia.edu/richard-billows\n",
      "Name: Francesco De Angelis, URL: https://classics.columbia.edu/francesco-de-angelis\n",
      "Name: Holger A. Klein, URL: https://classics.columbia.edu/holger-a-klein\n",
      "Name: Wolfgang Mann, URL: https://classics.columbia.edu/wolfgang-mann\n",
      "Name: Ioannis Mylonopoulos, URL: https://classics.columbia.edu/ioannis-mylonopoulos\n",
      "Name: Richard Sacks, URL: https://classics.columbia.edu/richard-sacks\n",
      "Name: Katja Maria Vogt, URL: https://classics.columbia.edu/katja-maria-vogt\n"
     ]
    }
   ],
   "source": [
    "def scrape_directory(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    names = []\n",
    "    bio_urls = []\n",
    "    titles = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"summary-item\"))\n",
    "            )\n",
    "\n",
    "            faculty_listings = driver.find_elements(By.CLASS_NAME, \"summary-item\")\n",
    "            for faculty in faculty_listings:\n",
    "                try:\n",
    "                    container_element = faculty.find_element(By.CLASS_NAME, \"summary-thumbnail-outer-container\")\n",
    "                    link_element = container_element.find_element(By.TAG_NAME, \"a\")\n",
    "\n",
    "                    name = link_element.get_attribute('data-title')\n",
    "\n",
    "                    link = link_element.get_attribute('href')\n",
    "                    bio_url = urljoin(url, link)\n",
    "\n",
    "                    names.append(name)\n",
    "                    titles.append(\"\")\n",
    "                    bio_urls.append(bio_url)\n",
    "                    print(f\"Name: {name}, URL: {bio_url}\")\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, \"Next\"))\n",
    "                )\n",
    "\n",
    "                retries = 5\n",
    "                for _ in range(retries):\n",
    "                    try:\n",
    "                        next_button.click()\n",
    "                        break\n",
    "                    except ElementClickInterceptedException:\n",
    "                        sleep(1)\n",
    "                else:\n",
    "                    print(\"Failed to click the 'Next' button after several retries.\")\n",
    "                    break\n",
    "\n",
    "            except (TimeoutException, NoSuchElementException):\n",
    "                # print(\"No 'Next' button found, or it's not clickable.\")\n",
    "                break\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout while waiting for page to load\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({'Name': names, 'Title': titles, 'url': bio_urls})\n",
    "\n",
    "    return df\n",
    "\n",
    "def extract_biographies(df):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Create a new column 'Research Summary'\n",
    "    df['Research Summary'] = None  # Initialize with None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        bio_url = row['url']\n",
    "        try:\n",
    "            driver.get(bio_url)\n",
    "            full_bio_text = \"\"\n",
    "\n",
    "            title = driver.find_element(By.TAG_NAME, \"h3\")\n",
    "            df.at[index, 'Title'] = title\n",
    "\n",
    "            # Find the original target section and extract text\n",
    "            try:\n",
    "                target_section = driver.find_element(By.TAG_NAME, \"ul\")\n",
    "                full_bio_text += target_section.text\n",
    "            except NoSuchElementException:\n",
    "                # If the target section is not found, continue without raising an error\n",
    "                pass\n",
    "\n",
    "            # Assign the 'Research Summary' to the corresponding row in the DataFrame\n",
    "            if full_bio_text:\n",
    "                df.at[index, 'Research Summary'] = full_bio_text\n",
    "            else:\n",
    "                df.at[index, 'Research Summary'] = None\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout while loading {bio_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract biography from {bio_url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return df\n",
    "\n",
    "url = \"https://classics.columbia.edu/profiles\"\n",
    "df = scrape_directory(url)\n",
    "df = extract_biographies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentence embedder model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n",
    "# Assuming 'Research Summary' column contains the text data\n",
    "df['Research Embedding'] = df['Research Summary'].apply(lambda x: model.encode([x])[0] if x else None)\n",
    "gdf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type WebElement is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save the list of dictionaries to a JSON file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaculty_data_classics.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type WebElement is not JSON serializable"
     ]
    }
   ],
   "source": [
    "gdf = df\n",
    "# Assuming 'gdf' is your original DataFrame\n",
    "\n",
    "# Convert the 'Research Embedding' column to a list of lists\n",
    "gdf['Research Embedding'] = gdf['Research Embedding'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else None)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "data_list = gdf.to_dict(orient='records')\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "with open('faculty_data_classics.json', 'w') as json_file:\n",
    "    json.dump(data_list, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>url</th>\n",
       "      <th>Research Summary</th>\n",
       "      <th>Research Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexander Alberro</td>\n",
       "      <td></td>\n",
       "      <td>https://arthistory.columbia.edu/content/alexan...</td>\n",
       "      <td>Alexander Alberro’s courses and graduate advis...</td>\n",
       "      <td>[0.04002338647842407, 0.033464401960372925, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zainab Bahrani</td>\n",
       "      <td></td>\n",
       "      <td>https://arthistory.columbia.edu/content/zainab...</td>\n",
       "      <td>Zainab Bahrani is the Edith Porada Professor a...</td>\n",
       "      <td>[0.005627704318612814, 0.09003138542175293, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frédérique Baumgartner</td>\n",
       "      <td></td>\n",
       "      <td>https://arthistory.columbia.edu/content/freder...</td>\n",
       "      <td>Frédérique Baumgartner’s research focuses on 1...</td>\n",
       "      <td>[-0.00390178756788373, 0.09777113795280457, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barry Bergdoll</td>\n",
       "      <td></td>\n",
       "      <td>https://arthistory.columbia.edu/content/barry-...</td>\n",
       "      <td>Professor Bergdoll's broad interests center on...</td>\n",
       "      <td>[0.04410383850336075, 0.12827448546886444, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diane Bodart</td>\n",
       "      <td></td>\n",
       "      <td>https://arthistory.columbia.edu/content/diane-...</td>\n",
       "      <td>Diane Bodart was educated in Art History at th...</td>\n",
       "      <td>[0.006267494987696409, -0.04520120471715927, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name Title  \\\n",
       "0       Alexander Alberro         \n",
       "1          Zainab Bahrani         \n",
       "2  Frédérique Baumgartner         \n",
       "3          Barry Bergdoll         \n",
       "4            Diane Bodart         \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://arthistory.columbia.edu/content/alexan...   \n",
       "1  https://arthistory.columbia.edu/content/zainab...   \n",
       "2  https://arthistory.columbia.edu/content/freder...   \n",
       "3  https://arthistory.columbia.edu/content/barry-...   \n",
       "4  https://arthistory.columbia.edu/content/diane-...   \n",
       "\n",
       "                                    Research Summary  \\\n",
       "0  Alexander Alberro’s courses and graduate advis...   \n",
       "1  Zainab Bahrani is the Edith Porada Professor a...   \n",
       "2  Frédérique Baumgartner’s research focuses on 1...   \n",
       "3  Professor Bergdoll's broad interests center on...   \n",
       "4  Diane Bodart was educated in Art History at th...   \n",
       "\n",
       "                                  Research Embedding  \n",
       "0  [0.04002338647842407, 0.033464401960372925, -0...  \n",
       "1  [0.005627704318612814, 0.09003138542175293, 0....  \n",
       "2  [-0.00390178756788373, 0.09777113795280457, -0...  \n",
       "3  [0.04410383850336075, 0.12827448546886444, 0.0...  \n",
       "4  [0.006267494987696409, -0.04520120471715927, 0...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file back into a DataFrame\n",
    "with open('faculty_data_classics.json', 'r') as json_file:\n",
    "    loaded_data_list = json.load(json_file)\n",
    "\n",
    "df = pd.DataFrame(loaded_data_list)\n",
    "\n",
    "# Now, gdf_loaded should have the 'Research Embedding' column in its original form\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "proposal = [\"\"\"\n",
    "medical image machine learning\n",
    "            \"\"\"]\n",
    "\n",
    "proposal_embedding = model.encode(proposal)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dot product for each row\n",
    "df['Dot Product'] = df['Research Embedding'].apply(lambda x: np.dot(proposal_embedding, x) if x is not None else None)\n",
    "\n",
    "# Sort DataFrame based on dot product scores in descending order\n",
    "df_sorted = df.sort_values(by='Dot Product', ascending=False)\n",
    "\n",
    "top_5 = df_sorted.head(5)\n",
    "\n",
    "print(top_5.iloc[0]['Research Summary'])\n",
    "\n",
    "top_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = proposal_embedding - top_5.iloc[0]['Research Embedding']\n",
    "# print(residual)\n",
    "proposal_embedding = residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = model.encode('king')\n",
    "norm = np.linalg.norm(king)\n",
    "king = king / norm\n",
    "\n",
    "man = model.encode('man')\n",
    "norm = np.linalg.norm(man)\n",
    "man = man / norm\n",
    "\n",
    "woman = model.encode('woman')\n",
    "norm = np.linalg.norm(woman)\n",
    "woman = woman / norm\n",
    "\n",
    "queen = model.encode('queen')\n",
    "norm = np.linalg.norm(queen)\n",
    "queen = queen / norm\n",
    "\n",
    "queen_test = king - man + woman\n",
    "norm = np.linalg.norm(queen_test)\n",
    "queen_test = queen_test / norm\n",
    "\n",
    "print('\\'king - man + woman\\' match to \\'king\\': ', np.dot(king, queen_test))\n",
    "print('\\'king - man + woman\\' match to \\'queen\\': ', np.dot(queen, queen_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dot product for each row\n",
    "df['Dot Product'] = df['Research Embedding'].apply(lambda x: np.dot(proposal_embedding, x) if x is not None else None)\n",
    "\n",
    "# Sort DataFrame based on dot product scores in descending order\n",
    "df_sorted = df.sort_values(by='Dot Product', ascending=False)\n",
    "\n",
    "top_5 = df_sorted.head(5)\n",
    "\n",
    "print(top_5.iloc[0]['Research Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Dot Product'])\n",
    "df.to_csv('faculty_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "def create_database():\n",
    "    conn = sqlite3.connect('biographies.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS biographies (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            url TEXT UNIQUE,\n",
    "            biography TEXT\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_biography(url, biography):\n",
    "    conn = sqlite3.connect('biographies.db')\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"INSERT INTO biographies (url, biography) VALUES (?, ?)\", (url, biography))\n",
    "        conn.commit()\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"URL already exists in database: {url}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def extract_biographies(bio_urls):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for bio_url in bio_urls:\n",
    "        try:\n",
    "            driver.get(bio_url)\n",
    "            full_bio_text = \"\"\n",
    "\n",
    "            try:\n",
    "                body_section = driver.find_element(By.CLASS_NAME, 'body.col-lg-7')\n",
    "                full_bio_text += body_section.text + \" \"\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                target_section = driver.find_element(By.CLASS_NAME, 'col-lg-7.entity.entity-paragraphs-item.paragraphs-item-content')\n",
    "                full_bio_text += target_section.text\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            if full_bio_text:\n",
    "                print(f\"Storing biography from {bio_url}\")\n",
    "                insert_biography(bio_url, full_bio_text)\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout while loading {bio_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract biography from {bio_url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# Create the database and table\n",
    "create_database()\n",
    "\n",
    "# Assuming you have a list of bio URLs\n",
    "bio_urls = [\"your_list_of_bio_urls_here\"]\n",
    "extract_biographies(bio_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
