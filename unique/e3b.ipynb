{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.39.2)\n",
      "Requirement already satisfied: tqdm in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n",
    "%pip install pandas\n",
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolepi/Documents/Wing/find-the-expert/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "from time import sleep\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: , Title: , URL: https://www.nybg.org/person/michael-balick/\n",
      "Name: BENDESKY, ANDRÉS, Title: ASSISTANT PROFESSOR, URL: https://e3b.columbia.edu/faculty/andres-bendesky/\n",
      "Name: , Title: , URL: http://www.amnh.org/our-research/staff-directory/mary-e.-blair\n",
      "Name: , Title: , URL: http://www.ldeo.columbia.edu/user/nboelman\n",
      "Name: BRODIE, BEKKA, Title: M.A. PROGRAM DIRECTOR, LECTURER, URL: https://e3b.columbia.edu/faculty/bekka-brodie/\n",
      "Name: , Title: , URL: http://www.amnh.org/our-research/staff-directory/frank-t.-burbrink\n",
      "Name: , Title: , URL: https://biology.barnard.edu/profiles/hilary-callahan\n",
      "Name: , Title: , URL: http://www.columbia.edu/~sc32/index.html\n",
      "Name: CORDS, MARINA, Title: PROFESSOR, URL: https://e3b.columbia.edu/faculty/marina-cords/\n",
      "Name: , Title: , URL: http://www.amnh.org/our-research/staff-directory/joel-l.-cracraft\n",
      "Name: , Title: , URL: https://www.amnh.org/research/staff-directory/georgina-cullman\n",
      "Name: , Title: , URL: https://blogs.ei.columbia.edu/2017/07/14/faculty-profile-lisa-dale/\n",
      "Name: , Title: , URL: https://www.ecohealthalliance.org/personnel/dr-peter-daszak\n",
      "Name: DEFRIES, RUTH, Title: UNIVERSITY PROFESSOR; DENNING FAMILY PROFESSOR OF SUSTAINABLE DEVELOPMENT, URL: https://e3b.columbia.edu/faculty/ruth-defries/\n",
      "Name: DIUK-WASSER, MARIA, Title: PROFESSOR, URL: https://e3b.columbia.edu/faculty/maria-diuk-wasser/\n",
      "Name: EATON, DEREN, Title: ASSISTANT PROFESSOR, URL: https://e3b.columbia.edu/faculty/deren-eaton/\n",
      "Name: , Title: , URL: https://sipa.columbia.edu/faculty/adela-j-gondek\n",
      "Name: GRIFFIN, KEVIN L., Title: PROFESSOR, URL: https://e3b.columbia.edu/faculty/kevin-l-griffin/\n",
      "Name: , Title: , URL: https://www.caryinstitute.org/science/our-scientists/dr-winslow-d-hansen\n",
      "Name: , Title: , URL: https://kelleylab.biology.columbia.edu/\n",
      "Name: , Title: , URL: http://sarakross.weebly.com/\n",
      "Name: , Title: , URL: https://barnard.edu/profiles/allison-lopatkin\n",
      "Name: , Title: , URL: https://www.amnh.org/research/staff-directory/suzanne-macey\n",
      "Name: , Title: , URL: https://www.amnh.org/research/staff-directory/anna-macpherson\n",
      "Name: , Title: , URL: https://www.nybg.org/person/alex-c-mcalvay/\n",
      "Name: MENGE, DUNCAN, Title: ASSOCIATE PROFESSOR, URL: https://e3b.columbia.edu/faculty/duncan-menge/\n",
      "Name: , Title: , URL: https://biology.barnard.edu/profiles/brian-morton\n",
      "Name: NAEEM, SHAHID, Title: PROFESSOR, URL: https://e3b.columbia.edu/faculty/shahid-naeem/\n",
      "Name: , Title: , URL: https://www.ecohealthalliance.org/personnel/dr-kevin-j-olival\n",
      "Name: , Title: , URL: https://www.ldeo.columbia.edu/~polsen/nbcp/peo.cv1.html\n",
      "Name: PALMER, MATTHEW, Title: SENIOR LECTURER, URL: https://e3b.columbia.edu/faculty/matthew-palmer/\n",
      "Name: , Title: , URL: http://www.ldeo.columbia.edu/user/peteet\n",
      "Name: , Title: , URL: https://biology.barnard.edu/profiles/alison-pischedda\n",
      "Name: , Title: , URL: https://www.biology.columbia.edu/people/pollack\n",
      "Name: , Title: , URL: https://rcss.scienceandsociety.columbia.edu/people/marya-pollack\n",
      "Name: , Title: , URL: http://www.amnh.org/our-research/staff-directory/christopher-j.-raxworthy\n",
      "Name: , Title: , URL: http://research.amnh.org/users/rfr/\n",
      "Name: , Title: , URL: https://e3b.columbia.edu/faculty/howard-rosenbaum/\n",
      "Name: , Title: , URL: https://www.ecohealthalliance.org/personnel/dr-melinda-mindy-rostal\n",
      "Name: RUBENSTEIN, DUSTIN R., Title: PROFESSOR; DIRECTOR OF GRADUATE STUDIES, URL: https://e3b.columbia.edu/faculty/dustin-r-rubenstein/\n",
      "Name: , Title: , URL: http://blackrockforest.org/about/staff\n",
      "Name: , Title: , URL: https://chadseewagen.weebly.com/\n",
      "Name: SHAPIRO, JILL, Title: SENIOR LECTURER, URL: https://e3b.columbia.edu/faculty/jill-shapiro/\n",
      "Name: , Title: , URL: https://www.fourthfloorornithology.com/\n",
      "Name: URIARTE, MARIA, Title: PROFESSOR; DEPARTMENT CHAIR, URL: https://e3b.columbia.edu/faculty/maria-uriarte/\n",
      "Name: , Title: , URL: https://e3b.columbia.edu/faculty/www.jessicalwarelab.com\n",
      "Name: , Title: , URL: https://paige-west.com/\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n",
      "An error occurred while processing the bio section: name 'info_sections' is not defined\n"
     ]
    }
   ],
   "source": [
    "def scrape_directory(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    names = []\n",
    "    bio_urls = []\n",
    "    titles = []\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"faculty-excerpt\"))\n",
    "            )\n",
    "\n",
    "            faculty_listings = driver.find_elements(By.CLASS_NAME, \"faculty-excerpt\")\n",
    "            for faculty in faculty_listings:\n",
    "                try:\n",
    "                    name_element = faculty.find_element(By.CLASS_NAME, \"faculty-name\")\n",
    "                    named = name_element.find_element(By.TAG_NAME, \"a\")\n",
    "                    name = named.text.strip()\n",
    "\n",
    "                    # Extracting the bio URL\n",
    "                    bio_url = named.get_attribute('href')\n",
    "\n",
    "                    title_element = faculty.find_element(By.CLASS_NAME, \"faculty-affiliation\")\n",
    "                    title = title_element.text.strip()\n",
    "\n",
    "                    names.append(name)\n",
    "                    titles.append(title)\n",
    "                    bio_urls.append(bio_url)\n",
    "                    print(f\"Name: {name}, Title: {title}, URL: {bio_url}\")\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, \"Next\"))\n",
    "                )\n",
    "\n",
    "                retries = 5\n",
    "                for _ in range(retries):\n",
    "                    try:\n",
    "                        next_button.click()\n",
    "                        break\n",
    "                    except ElementClickInterceptedException:\n",
    "                        sleep(1)\n",
    "                else:\n",
    "                    print(\"Failed to click the 'Next' button after several retries.\")\n",
    "                    break\n",
    "\n",
    "            except (TimeoutException, NoSuchElementException):\n",
    "                # print(\"No 'Next' button found, or it's not clickable.\")\n",
    "                break\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout while waiting for page to load\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({'Name': names, 'Title': titles, 'url': bio_urls})\n",
    "\n",
    "    return df\n",
    "\n",
    "def extract_biographies(df):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Create a new column 'Research Summary'\n",
    "    df['Research Summary'] = None  # Initialize with None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        bio_url = row['url']\n",
    "        try:\n",
    "            driver.get(bio_url)\n",
    "            full_bio_text = \"\"\n",
    "\n",
    "            try:\n",
    "                # Find all elements that could contain the required sections\n",
    "                potential_sections = driver.find_elements(By.CLASS_NAME, \"info-section\")\n",
    "\n",
    "                research_interests_started = False\n",
    "                selected_publications_reached = False\n",
    "                bio_text = \"\"\n",
    "\n",
    "                # Iterate through all potential sections to extract the relevant text\n",
    "                for section in info_sections:\n",
    "                    # Check if the section is 'Research Description' or 'Representative Publications'\n",
    "                    field_label = section.find_element(By.CLASS_NAME, \"field-label\").text\n",
    "                    if field_label in [\"Research Description\", \"Representative Publications\"]:\n",
    "                        # Find all <p> tags within this section and concatenate their text\n",
    "                        paragraphs = section.find_elements(By.TAG_NAME, \"p\")\n",
    "                        section_text = \"\\n\".join([p.text for p in paragraphs])\n",
    "\n",
    "                        # Add this section's text to the full bio text, with a heading\n",
    "                        full_bio_text += f\"{field_label}:\\n{section_text}\\n\\n\"\n",
    "\n",
    "                # Trim the last newline characters\n",
    "                full_bio_text = full_bio_text.rstrip()\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle any errors that might occur during the extraction\n",
    "                print(f\"An error occurred while processing the bio section: {e}\")\n",
    "\n",
    "            # Assign the 'Research Summary' to the corresponding row in the DataFrame\n",
    "            if full_bio_text:\n",
    "                df.at[index, 'Research Summary'] = full_bio_text\n",
    "            else:\n",
    "                df.at[index, 'Research Summary'] = None\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout while loading {bio_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract biography from {bio_url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return df\n",
    "\n",
    "url = \"https://e3b.columbia.edu/faculty/\"\n",
    "df = scrape_directory(url)\n",
    "df = extract_biographies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentence embedder model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n",
    "# Assuming 'Research Summary' column contains the text data\n",
    "df['Research Embedding'] = df['Research Summary'].apply(lambda x: model.encode([x])[0] if x else None)\n",
    "gdf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df\n",
    "# Assuming 'gdf' is your original DataFrame\n",
    "\n",
    "# Convert the 'Research Embedding' column to a list of lists\n",
    "gdf['Research Embedding'] = gdf['Research Embedding'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else None)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "data_list = gdf.to_dict(orient='records')\n",
    "\n",
    "# Save the list of dictionaries to a JSON file\n",
    "with open('faculty_data_e3b.json', 'w') as json_file:\n",
    "    json.dump(data_list, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>url</th>\n",
       "      <th>Research Summary</th>\n",
       "      <th>Research Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nasr Abdo</td>\n",
       "      <td></td>\n",
       "      <td>https://mesaas.columbia.edu/faculty-directory/...</td>\n",
       "      <td>Nasr got his bachelor’s degree in Education fr...</td>\n",
       "      <td>[0.04447173699736595, 0.028266340494155884, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mohamed Abdou</td>\n",
       "      <td></td>\n",
       "      <td>https://mesaas.columbia.edu/faculty-directory/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ouijdane Absi</td>\n",
       "      <td></td>\n",
       "      <td>https://mesaas.columbia.edu/faculty-directory/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aftab Ahmad</td>\n",
       "      <td></td>\n",
       "      <td>https://mesaas.columbia.edu/faculty-directory/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May Ahmar</td>\n",
       "      <td></td>\n",
       "      <td>https://mesaas.columbia.edu/faculty-directory/...</td>\n",
       "      <td>May Ahmar is a Senior Lecturer in Arabic in th...</td>\n",
       "      <td>[0.034430164843797684, 0.03392524644732475, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Title                                                url  \\\n",
       "0      Nasr Abdo        https://mesaas.columbia.edu/faculty-directory/...   \n",
       "1  Mohamed Abdou        https://mesaas.columbia.edu/faculty-directory/...   \n",
       "2  Ouijdane Absi        https://mesaas.columbia.edu/faculty-directory/...   \n",
       "3    Aftab Ahmad        https://mesaas.columbia.edu/faculty-directory/...   \n",
       "4      May Ahmar        https://mesaas.columbia.edu/faculty-directory/...   \n",
       "\n",
       "                                    Research Summary  \\\n",
       "0  Nasr got his bachelor’s degree in Education fr...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4  May Ahmar is a Senior Lecturer in Arabic in th...   \n",
       "\n",
       "                                  Research Embedding  \n",
       "0  [0.04447173699736595, 0.028266340494155884, -0...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4  [0.034430164843797684, 0.03392524644732475, -0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file back into a DataFrame\n",
    "with open('faculty_data_e3b.json', 'r') as json_file:\n",
    "    loaded_data_list = json.load(json_file)\n",
    "\n",
    "df = pd.DataFrame(loaded_data_list)\n",
    "\n",
    "# Now, gdf_loaded should have the 'Research Embedding' column in its original form\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "proposal = [\"\"\"\n",
    "medical image machine learning\n",
    "            \"\"\"]\n",
    "\n",
    "proposal_embedding = model.encode(proposal)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dot product for each row\n",
    "df['Dot Product'] = df['Research Embedding'].apply(lambda x: np.dot(proposal_embedding, x) if x is not None else None)\n",
    "\n",
    "# Sort DataFrame based on dot product scores in descending order\n",
    "df_sorted = df.sort_values(by='Dot Product', ascending=False)\n",
    "\n",
    "top_5 = df_sorted.head(5)\n",
    "\n",
    "print(top_5.iloc[0]['Research Summary'])\n",
    "\n",
    "top_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = proposal_embedding - top_5.iloc[0]['Research Embedding']\n",
    "# print(residual)\n",
    "proposal_embedding = residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = model.encode('king')\n",
    "norm = np.linalg.norm(king)\n",
    "king = king / norm\n",
    "\n",
    "man = model.encode('man')\n",
    "norm = np.linalg.norm(man)\n",
    "man = man / norm\n",
    "\n",
    "woman = model.encode('woman')\n",
    "norm = np.linalg.norm(woman)\n",
    "woman = woman / norm\n",
    "\n",
    "queen = model.encode('queen')\n",
    "norm = np.linalg.norm(queen)\n",
    "queen = queen / norm\n",
    "\n",
    "queen_test = king - man + woman\n",
    "norm = np.linalg.norm(queen_test)\n",
    "queen_test = queen_test / norm\n",
    "\n",
    "print('\\'king - man + woman\\' match to \\'king\\': ', np.dot(king, queen_test))\n",
    "print('\\'king - man + woman\\' match to \\'queen\\': ', np.dot(queen, queen_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dot product for each row\n",
    "df['Dot Product'] = df['Research Embedding'].apply(lambda x: np.dot(proposal_embedding, x) if x is not None else None)\n",
    "\n",
    "# Sort DataFrame based on dot product scores in descending order\n",
    "df_sorted = df.sort_values(by='Dot Product', ascending=False)\n",
    "\n",
    "top_5 = df_sorted.head(5)\n",
    "\n",
    "print(top_5.iloc[0]['Research Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Dot Product'])\n",
    "df.to_csv('faculty_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "def create_database():\n",
    "    conn = sqlite3.connect('biographies.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS biographies (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            url TEXT UNIQUE,\n",
    "            biography TEXT\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_biography(url, biography):\n",
    "    conn = sqlite3.connect('biographies.db')\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"INSERT INTO biographies (url, biography) VALUES (?, ?)\", (url, biography))\n",
    "        conn.commit()\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"URL already exists in database: {url}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def extract_biographies(bio_urls):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    for bio_url in bio_urls:\n",
    "        try:\n",
    "            driver.get(bio_url)\n",
    "            full_bio_text = \"\"\n",
    "\n",
    "            try:\n",
    "                body_section = driver.find_element(By.CLASS_NAME, 'body.col-lg-7')\n",
    "                full_bio_text += body_section.text + \" \"\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                target_section = driver.find_element(By.CLASS_NAME, 'col-lg-7.entity.entity-paragraphs-item.paragraphs-item-content')\n",
    "                full_bio_text += target_section.text\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            if full_bio_text:\n",
    "                print(f\"Storing biography from {bio_url}\")\n",
    "                insert_biography(bio_url, full_bio_text)\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout while loading {bio_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract biography from {bio_url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# Create the database and table\n",
    "create_database()\n",
    "\n",
    "# Assuming you have a list of bio URLs\n",
    "bio_urls = [\"your_list_of_bio_urls_here\"]\n",
    "extract_biographies(bio_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
